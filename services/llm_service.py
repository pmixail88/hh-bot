import os
import sys
import aiohttp
import asyncio
import json
from dotenv import load_dotenv
from typing import Dict, Any, Optional
from core.config import get_config
from utils.logger import get_logger
# from core import config  # ‚Üê –î–û–ë–ê–í–¨ –≠–¢–û

# –ó–ê–ì–†–£–ñ–ê–ï–ú .env —Ñ–∞–π–ª
load_dotenv()

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø—É—Ç–∏
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if parent_dir not in sys.path:
    sys.path.append(parent_dir)


logger = get_logger(__name__)

# –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∏–º–ø–æ—Ä—Ç CacheService
try:
    from services.cache import CacheService

    cache_available = True
except ImportError:
    logger.warning("CacheService –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é –ø—Ä–æ—Å—Ç–æ–π –∫—ç—à")

class CacheService:
    def __init__(self):
        self.cache = {}

    async def get(self, key):
        return self.cache.get(key)

    async def set(self, key, value, expire=None):
        self.cache[key] = value

cache_available = False


logger = get_logger(__name__)


class LLMService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å LLM —á–µ—Ä–µ–∑ OpenRouter"""

    def __init__(self, config):
        self.base_url = config.base_url
        self.api_key = config.api_key
        self.model_name = config.model_name
        self.timeout = config.timeout
        self.max_tokens = config.max_tokens
        self.temperature = config.temperature

        logger.info(f"LLMService –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {self.model_name} –Ω–∞ {self.base_url}")

    async def _make_request(self, messages: list, max_tokens: int = None, temperature: float = None) -> Optional[str]:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ LLM API"""
        if not self.api_key:
            logger.error("API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
            return None

        url = f"{self.base_url}/chat/completions"

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://github.com/pmixail88/hh-bot",
            "X-Title": "HH Work Day Bot",
        }

        payload = {
            "model": self.model_name,
            "messages": messages,
            "max_tokens": max_tokens or self.max_tokens,
            "temperature": temperature or self.temperature,
        }

        try:
            timeout = aiohttp.ClientTimeout(total=self.timeout)

            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.post(url, headers=headers, json=payload) as response:

                    if response.status == 200:
                        data = await response.json()

                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
                        if "choices" in data and len(data["choices"]) > 0:
                            if "message" in data["choices"][0]:
                                return data["choices"][0]["message"]["content"].strip()
                            elif "text" in data["choices"][0]:
                                return data["choices"][0]["text"].strip()
                        elif "text" in data:
                            return data["text"].strip()
                        elif "response" in data:
                            return data["response"].strip()
                        else:
                            logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: {data}")
                            return None
                    else:
                        error_text = await response.text()
                        logger.error(f"–û—à–∏–±–∫–∞ API: {response.status} - {error_text}")
                        return None

        except aiohttp.ClientError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
            return None
        except asyncio.TimeoutError:
            logger.error("–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ LLM")
            return None
        except Exception as e:
            logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
            return None

    async def generate_resume(
        self, user_profile: Dict, vacancy_info: Dict, llm_settings: Dict = None
    ) -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∑—é–º–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM"""
        settings = llm_settings or {}
        api_key = settings.get("api_key") or self.api_key

        if not api_key:
            logger.info("API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é —à–∞–±–ª–æ–Ω")
            return self._get_template_resume(user_profile, vacancy_info)

        cache_key = f"resume:{hash(str(user_profile))}:{hash(str(vacancy_info))}"

        cached = await self.cache.get(cache_key)
        if cached:
            logger.info("‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—é–º–µ –≤ –∫—ç—à–µ")
            return cached

        try:
            prompt = self._create_resume_prompt(user_profile, vacancy_info)

            call_settings = {
                "api_key": api_key,
                "model_name": settings.get("model_name", self.model_name),
                "base_url": settings.get("base_url", self.base_url),
                "temperature": settings.get("temperature", self.temperature),
                "max_tokens": settings.get("max_tokens", self.max_tokens),
            }

            result = await self._call_llm_api(prompt, call_settings)

            if result:
                await self.cache.set(cache_key, result, expire=3600)
                return result
            return self._get_template_resume(user_profile, vacancy_info)

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∑—é–º–µ: {e}")
            return self._get_template_resume(user_profile, vacancy_info)

    async def generate_cover_letter(
        self, user_profile: Dict, vacancy_info: Dict, llm_settings: Dict = None
    ) -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∏—Å—å–º–∞"""
        settings = llm_settings or {}
        api_key = settings.get("api_key") or self.api_key

        if not api_key:
            logger.info("API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é —à–∞–±–ª–æ–Ω")
            return self._get_template_cover_letter(user_profile, vacancy_info)

        cache_key = f"cover_letter:{hash(str(user_profile))}:{hash(str(vacancy_info))}"

        cached = await self.cache.get(cache_key)
        if cached:
            logger.info("‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–∏—Å—å–º–æ –≤ –∫—ç—à–µ")
            return cached

        try:
            prompt = self._create_cover_letter_prompt(user_profile, vacancy_info)

            call_settings = {
                "api_key": api_key,
                "model_name": settings.get("model_name", self.model_name),
                "base_url": settings.get("base_url", self.base_url),
                "temperature": settings.get("temperature", self.temperature),
                "max_tokens": settings.get("max_tokens", self.max_tokens),
            }

            result = await self._call_llm_api(prompt, call_settings)

            if result:
                await self.cache.set(cache_key, result, expire=3600)
                return result
            return self._get_template_cover_letter(user_profile, vacancy_info)

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∏—Å—å–º–∞: {e}")
            return self._get_template_cover_letter(user_profile, vacancy_info)

    def _create_resume_prompt(self, user_profile: Dict, vacancy_info: Dict) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∑—é–º–µ"""
        return f"""
–°–æ–∑–¥–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Ä–µ–∑—é–º–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Ñ–∏–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –≤–∞–∫–∞–Ω—Å–∏–∏.

–ü–†–û–§–ò–õ–¨ –ö–ê–ù–î–ò–î–ê–¢–ê:
- –ò–º—è: {user_profile.get('full_name', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
- –ì–æ—Ä–æ–¥: {user_profile.get('city', '–ù–µ —É–∫–∞–∑–∞–Ω')}
- –ñ–µ–ª–∞–µ–º–∞—è –¥–æ–ª–∂–Ω–æ—Å—Ç—å: {user_profile.get('desired_position', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}
- –ù–∞–≤—ã–∫–∏: {user_profile.get('skills', '–ù–µ —É–∫–∞–∑–∞–Ω—ã')}
- –û–ø—ã—Ç –∏ –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è: {user_profile.get('base_resume', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}

–ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –í–ê–ö–ê–ù–°–ò–ò:
- –î–æ–ª–∂–Ω–æ—Å—Ç—å: {vacancy_info.get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}
- –ö–æ–º–ø–∞–Ω–∏—è: {vacancy_info.get('company_name', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}
- –û–ø–∏—Å–∞–Ω–∏–µ: {vacancy_info.get('description', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')[:1500]}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø:
1. –°—Ç—Ä—É–∫—Ç—É—Ä–∞: –§–ò–û –∏ –∫–æ–Ω—Ç–∞–∫—Ç—ã, –¶–µ–ª—å, –û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã, –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, –ù–∞–≤—ã–∫–∏, –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
2. –ê–¥–∞–ø—Ç–∏—Ä—É–π —Ä–µ–∑—é–º–µ –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –≤–∞–∫–∞–Ω—Å–∏—é
3. –ü–æ–¥—á–µ—Ä–∫–Ω–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –Ω–∞–≤—ã–∫–∏
4. –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —è–∑—ã–∫
5. –û–±—ä–µ–º: 500-1500 —Å–ª–æ–≤
6. –§–æ—Ä–º–∞—Ç: —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ —Ä–∞–∑–º–µ—Ç–∫–∏

–°–æ–∑–¥–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Ä–µ–∑—é–º–µ:
"""

    def _create_cover_letter_prompt(
        self, user_profile: Dict, vacancy_info: Dict
    ) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∏—Å—å–º–∞"""
        return f"""
–ù–∞–ø–∏—à–∏ —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–∏—Å—å–º–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –¥–ª—è –æ—Ç–∫–ª–∏–∫–∞ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é.

–ü–†–û–§–ò–õ–¨ –ö–ê–ù–î–ò–î–ê–¢–ê:
- –ò–º—è: {user_profile.get('full_name', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
- –ù–∞–≤—ã–∫–∏: {user_profile.get('skills', '–ù–µ —É–∫–∞–∑–∞–Ω—ã')}
- –û–ø—ã—Ç: {user_profile.get('base_resume', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}

–ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –í–ê–ö–ê–ù–°–ò–ò:
- –î–æ–ª–∂–Ω–æ—Å—Ç—å: {vacancy_info.get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}
- –ö–æ–º–ø–∞–Ω–∏—è: {vacancy_info.get('company_name', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}
- –û–ø–∏—Å–∞–Ω–∏–µ: {vacancy_info.get('description', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')[:1500]}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø:
1. –°—Ç—Ä—É–∫—Ç—É—Ä–∞: –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ, –í–≤–µ–¥–µ–Ω–∏–µ, –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º, –ú–æ—Ç–∏–≤–∞—Ü–∏—è, –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
2. –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ–±—Ä–∞—â–µ–Ω–∏–µ –∫ –∫–æ–º–ø–∞–Ω–∏–∏
3. –°—Å—ã–ª–∞–π—Å—è –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏
4. –ü–æ–¥—á–µ—Ä–∫–Ω–∏ 2-3 –∫–ª—é—á–µ–≤—ã—Ö –Ω–∞–≤—ã–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
5. –ü—Ä–æ—è–≤–∏ —ç–Ω—Ç—É–∑–∏–∞–∑–º –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–µ—Å
6. –û–±—ä–µ–º: 200-300 —Å–ª–æ–≤
7. –§–æ—Ä–º–∞—Ç: –¥–µ–ª–æ–≤–æ–µ –ø–∏—Å—å–º–æ

–ù–∞–ø–∏—à–∏ —É–±–µ–¥–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–∏—Å—å–º–æ:
"""

    async def _call_llm_api(self, prompt: str, llm_settings: Dict) -> Optional[str]:
        """–í—ã–∑–æ–≤ LLM API –¥–ª—è OpenRouter"""
        try:
            api_key = llm_settings.get("api_key", self.api_key)
            base_url = llm_settings.get("base_url", self.base_url)
            model_name = llm_settings.get("model_name", self.model_name)

            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}",
                "HTTP-Referer": "https://t.me/hr_assistant_bot",
                "X-Title": "HR Assistant Bot",
            }

            data = {
                "model": model_name,
                "messages": [
                    {
                        "role": "system",
                        "content": "–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π HR-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç —Å –æ–ø—ã—Ç–æ–º —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ä–µ–∑—é–º–µ –∏ —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∏—Å–µ–º. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.",
                    },
                    {"role": "user", "content": prompt},
                ],
                "temperature": llm_settings.get("temperature", self.temperature),
                "max_tokens": llm_settings.get("max_tokens", self.max_tokens),
                "top_p": 0.9,
            }

            async with aiohttp.ClientSession(timeout=self.timeout) as session:
                async with session.post(
                    f"{base_url}/chat/completions", headers=headers, json=data
                ) as response:

                    response_text = await response.text()

                    if response.status == 200:
                        try:
                            result = json.loads(response_text)
                            logger.debug(f"LLM Response keys: {list(result.keys())}")

                            # OpenRouter –º–æ–∂–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Ä–∞–∑–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                            if "choices" in result and len(result["choices"]) > 0:
                                return result["choices"][0]["message"]["content"]
                            elif (
                                "result" in result
                                and "alternatives" in result["result"]
                            ):
                                # –Ø–Ω–¥–µ–∫—Å GPT —Ñ–æ—Ä–º–∞—Ç
                                return result["result"]["alternatives"][0]["message"][
                                    "text"
                                ]
                            else:
                                logger.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: {result}")
                                return None
                        except json.JSONDecodeError as e:
                            logger.error(
                                f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}, —Ç–µ–∫—Å—Ç: {response_text[:200]}"
                            )
                            return None
                    else:
                        logger.error(
                            f"–û—à–∏–±–∫–∞ LLM API: {response.status}, —Ç–µ–∫—Å—Ç: {response_text[:500]}"
                        )
                        return None

        except asyncio.TimeoutError:
            logger.error("–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –≤—ã–∑–æ–≤–µ LLM API")
            return None
        except aiohttp.ClientError as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ LLM API: {e}")
            return None
        except Exception as e:
            logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ LLM API: {e}")
            return None

    def _get_template_resume(self, user_profile: Dict, vacancy_info: Dict) -> str:
        """–®–∞–±–ª–æ–Ω–Ω–æ–µ —Ä–µ–∑—é–º–µ –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ API"""
        return f"""
{user_profile.get('full_name', '–ò–º—è –§–∞–º–∏–ª–∏—è')}
–ì–æ—Ä–æ–¥: {user_profile.get('city', '–ù–µ —É–∫–∞–∑–∞–Ω')}
–¢–µ–ª–µ—Ñ–æ–Ω: [–í–∞—à —Ç–µ–ª–µ—Ñ–æ–Ω]
Email: [–í–∞—à email]

–¶–µ–ª—å: –ó–∞–º–µ—â–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏ {vacancy_info.get('name', '–≤–æ—Å–ø–∏—Ç–∞—Ç–µ–ª—è')}

–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã:
{user_profile.get('base_resume', '–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã –≤ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π —Å—Ñ–µ—Ä–µ.')}

–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ: [–í–∞—à–µ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ]

–ù–∞–≤—ã–∫–∏:
{user_profile.get('skills', '–ù–∞–≤—ã–∫–∏ —Ä–∞–±–æ—Ç—ã —Å –¥–µ—Ç—å–º–∏, –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π, –≤–µ–¥–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏')}

–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è: [–í–∞—à–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è]
"""

    def _get_template_cover_letter(self, user_profile: Dict, vacancy_info: Dict) -> str:
        """–®–∞–±–ª–æ–Ω–Ω–æ–µ —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–∏—Å—å–º–æ"""
        return f"""
–£–≤–∞–∂–∞–µ–º—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª–∏ –∫–æ–º–ø–∞–Ω–∏–∏ {vacancy_info.get('company_name', '')}!

–ú–µ–Ω—è –∑–æ–≤—É—Ç {user_profile.get('full_name', '–ò–º—è –§–∞–º–∏–ª–∏—è')}, –∏ —è —Ö–æ—Ç–µ–ª(–∞) –±—ã –≤—ã—Ä–∞–∑–∏—Ç—å —Å–≤–æ—é –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –≤ –≤–∞–∫–∞–Ω—Å–∏–∏ {vacancy_info.get('name', '–≤–æ—Å–ø–∏—Ç–∞—Ç–µ–ª—è')}.

–ú–æ–π –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã –≤–∫–ª—é—á–∞–µ—Ç: {user_profile.get('base_resume', '—Ä–∞–±–æ—Ç—É —Å –¥–µ—Ç—å–º–∏')}. 
–Ø –æ–±–ª–∞–¥–∞—é —Å–ª–µ–¥—É—é—â–∏–º–∏ –Ω–∞–≤—ã–∫–∏: {user_profile.get('skills', '–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —É—á–µ–±–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞')}.

–ë—É–¥—É —Ä–∞–¥(–∞) –æ–±—Å—É–¥–∏—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–∞ –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏.

–° —É–≤–∞–∂–µ–Ω–∏–µ–º,
{user_profile.get('full_name', '–ò–º—è –§–∞–º–∏–ª–∏—è')}
"""

    async def test_connection(self, llm_settings: Dict = None) -> bool:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LLM API"""
        try:
            settings = llm_settings or {}
            api_key = settings.get("api_key") or self.api_key

            if not api_key:
                logger.warning("–ù–µ—Ç API –∫–ª—é—á–∞ –¥–ª—è —Ç–µ—Å—Ç–∞")
                return False

            test_prompt = "–û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º –Ω–∞ —Ä—É—Å—Å–∫–æ–º: '–≥–æ—Ç–æ–≤'"

            test_settings = {
                "api_key": api_key,
                "model_name": settings.get("model_name", self.model_name),
                "base_url": settings.get("base_url", self.base_url),
                "temperature": 0.1,
                "max_tokens": 10,
            }

            result = await self._call_llm_api(test_prompt, test_settings)
            return result is not None and "–≥–æ—Ç–æ–≤" in result.lower()

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ LLM: {e}")
            return False


# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
async def test():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LLM —Å–µ—Ä–≤–∏—Å–∞"""
    print("üß™ –¢–ï–°–¢ LLM –°–ï–†–í–ò–°–ê")
    print("=" * 50)

    try:
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        config = get_config()

        print(f"API –∫–ª—é—á: {'‚úÖ –ï—Å—Ç—å' if config.llm.api_key else '‚ùå –ù–µ—Ç'}")
        print(f"–ú–æ–¥–µ–ª—å: {config.llm.model_name}")
        print(f"Base URL: {config.llm.base_url}")

        if not config.llm.api_key:
            print("‚ùå API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –≤ .env —Ñ–∞–π–ª–µ!")
            return

        # –°–æ–∑–¥–∞–µ–º —Å–µ—Ä–≤–∏—Å —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
        llm = LLMService(config.llm)

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        print("\nüîç –¢–µ—Å—Ç–∏—Ä—É—é –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ LLM...")
        connected = await llm.test_connection()

        if connected:
            print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ LLM: –†–ê–ë–û–¢–ê–ï–¢")

            # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç
            print("\nüîç –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å...")
            test_messages = [
                {"role": "system", "content": "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç."},
                {"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç! –û—Ç–≤–µ—Ç—å –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–æ."},
            ]

            response = await llm._make_request(test_messages, max_tokens=30)
            if response:
                print(f"‚úÖ –û—Ç–≤–µ—Ç LLM: {response}")
            else:
                print("‚ùå –ù–µ—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM")

        else:
            print("‚ùå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ LLM: –ù–ï –†–ê–ë–û–¢–ê–ï–¢")
            print("\nüîß –ü—Ä–æ–≤–µ—Ä—å—Ç–µ:")
            print("1. API –∫–ª—é—á –≤ .env —Ñ–∞–π–ª–µ")
            print("2. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É")
            print("3. –ß—Ç–æ –º–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞: mistralai/mistral-7b-instruct:free")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç
    asyncio.run(test())
